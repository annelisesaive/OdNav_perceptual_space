{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4d4fd2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from utils_dist_corr import *\n",
    "import pingouin as pg\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dcdd273",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '/Users/alouette/Documents/Perceptual_Space_ALS/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e5710",
   "metadata": {},
   "source": [
    "## Characterize geometry of perceptual space\n",
    "Euclidian distance based on 2 first dimension of PCA space \n",
    "\n",
    "Take coordinates computed using v = all mod (all 3 modalities at the same time in the same PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b864c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "stims = ['music','face','odor']\n",
    "nb_stim = 18\n",
    "\n",
    "for stim in stims:\n",
    "    files_pca = [f for f in os.listdir(path_data + 'df_pca/') if f.endswith('ALL_PCA.csv')]\n",
    "\n",
    "    all_dist = np.zeros((nb_pairs(nb_stim),len(files_pca)))\n",
    "    all_sub = []\n",
    "    for i, f in enumerate(files_pca):\n",
    "        df = pd.read_csv(path_data+'df_pca/'+ f, index_col=0)\n",
    "        df_sel = df.loc[df.stimulus_type == stim]\n",
    "        pairs = define_pairs(df_sel.stimulus_name)\n",
    "        dist = compute_all_dist(df_sel, pairs, name_col='stimulus_name',\n",
    "                           x_col='coord.Dim.1', y_col='coord.Dim.2')\n",
    "        all_dist[:,i] += dist\n",
    "        all_sub.append(df.subject.values[0])\n",
    "\n",
    "    data_df = np.concatenate((np.array(pairs),all_dist),axis=1)\n",
    "    df_all = pd.DataFrame(data=data_df, columns=['p0','p1']+all_sub)\n",
    "    df_all.to_csv(path_data+'Python/all_dist_stim='+stim+'_v=allmod.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3ec37",
   "metadata": {},
   "source": [
    "#### Compute distances BETWEEN modality spaces (ex: all distances between odors and the rest of stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c3c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_pca = [f for f in os.listdir(path_data + 'df_pca/') if f.endswith('ALL_PCA.csv')]\n",
    "\n",
    "all_dist = np.zeros((972, len(files_pca)))\n",
    "all_sub = []\n",
    "for i, f in enumerate(files_pca):\n",
    "    df = pd.read_csv(path_data+'df_pca/'+ f, index_col=0)\n",
    "    df['stim_name2'] = ['O'+name if name[0] not in ('M','V') else name for name in df.stimulus_name]\n",
    "    pairs = define_pairs_diff(df.stim_name2)\n",
    "    dist = compute_all_dist(df, pairs, name_col='stim_name2',\n",
    "                       x_col='coord.Dim.1', y_col='coord.Dim.2')\n",
    "    all_dist[:,i] += dist\n",
    "    all_sub.append(df.subject.values[0])\n",
    "\n",
    "data_df = np.concatenate((np.array(pairs),all_dist),axis=1)\n",
    "df_all = pd.DataFrame(data=data_df, columns=['p0','p1']+all_sub)\n",
    "df_all.to_csv(path_data+'Python/all_dist_BTW_stim_v=allmod.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e20d342",
   "metadata": {},
   "source": [
    "## Compare perceptual space\n",
    "Compare the consistency (R) btw space across subject for each sensory modality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb12be2",
   "metadata": {},
   "source": [
    "### Compute perceptual spaces' consistency across subjects - WITHIN MODALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = path_data+'Python/all_dist_stim={}_v=allmod.csv'\n",
    "stims = ['music','face','odor']\n",
    "\n",
    "space_r = []\n",
    "for stim in stims:\n",
    "    df = pd.read_csv(path_df.format(stim), index_col=0)\n",
    "    subj = [c for c in df.columns if c not in ['p0','p1']]\n",
    "    pairs_su = define_pairs(subj)\n",
    "    corr = compute_all_R(df, pairs_su, meth='spearman')\n",
    "    space_r.append(corr) \n",
    "space_r = np.transpose(np.vstack(space_r))\n",
    "\n",
    "df_r_var = pd.DataFrame(space_r, columns=stims)\n",
    "print(df_r_var.describe())\n",
    "df_r_var.to_csv(path_data+'Python/btw_subj_consistency_allstims_v=allmod.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2221c2",
   "metadata": {},
   "source": [
    "### Compute perceptual spaces' consistency across subjects - BETWEEN MODALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6753437",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = path_data+'Python/all_dist_BTW_stim_v=allmod.csv'\n",
    "stims_to_key = {'music':'M',\n",
    "                'face': 'V',\n",
    "                'odor':'O'}\n",
    "\n",
    "df = pd.read_csv(path_df.format(stim), index_col=0)\n",
    "subj = [c for c in df.columns if c not in ['p0','p1']]\n",
    "pairs_su = define_pairs(subj)\n",
    "\n",
    "space_r = []\n",
    "for stim in stims_to_key:\n",
    "    key = stims_to_key[stim]\n",
    "    df_sel = df.loc[df['p0'].str.contains(key) | df['p1'].str.contains(key)]\n",
    "    \n",
    "    corr = compute_all_R(df_sel, pairs_su, meth='spearman')\n",
    "    space_r.append(corr) \n",
    "space_r = np.transpose(np.vstack(space_r))\n",
    "df_r_var = pd.DataFrame(space_r, columns=stims)\n",
    "print(df_r_var.describe())\n",
    "df_r_var.to_csv(path_data+'Python/btw_subj_consistency_BTW_stim_v=allmod.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b92f9f4",
   "metadata": {},
   "source": [
    "### Compare consistencies across modality (+ paired links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582cd7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pingouin as pg \n",
    "\n",
    "df_r_var = pd.read_csv(path_data+'Python/btw_subj_consistency_BTW_stim_v=allmod.csv')\n",
    "\n",
    "# Plot results \n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(5,4))\n",
    "df_r_var.boxplot(column=stims, ax=axes)\n",
    "\n",
    "# Compute 1-way repeated measures ANOVA\n",
    "df_r_stats = df_r_var.melt()\n",
    "df_r_stats.columns = ['stims','btw_su_corr']\n",
    "df_r_stats['su_pairs'] = np.concatenate([np.arange(0,df_r_var.shape[0],1)]*3)\n",
    "anova = pg.rm_anova(data=df_r_stats, dv='btw_su_corr', within='stims',\n",
    "                    subject='su_pairs')\n",
    "pg.print_table(anova, floatfmt='.3f')\n",
    "\n",
    "# Bonf-corrected post hocs with Hedges'g effect size\n",
    "posthoc = pg.pairwise_tests(data=df_r_stats, dv='btw_su_corr', within='stims',\n",
    "                            subject='su_pairs', padjust='bonf')\n",
    "pg.print_table(posthoc, floatfmt='.3f')\n",
    "\n",
    "# Pairwise correlations between sensory modality\n",
    "pair_r = pg.pairwise_corr(df_r_var, method='pearson')\n",
    "print(pair_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc28e4",
   "metadata": {},
   "source": [
    "### Compare perceptual spaces' size and dispersion v=bymod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c867522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stims = ['music','face','odor']\n",
    "cols_to_sel = ['%var_cum','pol_surf','circ_surf','avg_d']\n",
    "\n",
    "files_pca = [f for f in os.listdir(path_data + 'df_pca/') if f.endswith('_PCA_sum.csv')]\n",
    "    \n",
    "all_pca = np.zeros((len(files_pca),4))\n",
    "infos = np.array([])\n",
    "for i,f in enumerate(files_pca):\n",
    "    splits = [sp.split('_') for sp in f.split('=')]\n",
    "    s_splits = np.array((splits[1][0],splits[2][0]))\n",
    "    infos = np.vstack((infos,s_splits)) if np.size(infos) else np.array(s_splits)\n",
    "    \n",
    "    df = pd.read_csv(path_data+'df_pca/'+f, index_col=0)\n",
    "    df.columns = ['cos2','%var','%var_cum','pol_surf','circ_surf','x0','y0','avg_d']\n",
    "    sel = df[cols_to_sel].loc[['comp 2']].values[0]\n",
    "    all_pca[i,:] += sel\n",
    "\n",
    "data_df = np.concatenate((infos,all_pca), axis=1)\n",
    "df_all = pd.DataFrame(data=data_df, columns=['subject','stim']+cols_to_sel)\n",
    "print(df_all)\n",
    "df_all.to_csv(path_data+'Python/all_spaces_geometry.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327a3cd",
   "metadata": {},
   "source": [
    "### Compare perceptual spaces' size and dispersion v=allmod\n",
    "Average distance and circle surface NOT included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_pca = [f for f in os.listdir(path_data + 'df_pca/') if f.endswith('ALL_PCA_sum.csv')]\n",
    "    \n",
    "all_pca = np.zeros((len(files_pca),3))\n",
    "infos = np.array([])\n",
    "for i,f in enumerate(files_pca):\n",
    "    splits = [sp.split('_') for sp in f.split('=')]\n",
    "    s_splits = np.array((splits[1][0]))\n",
    "    infos = np.vstack((infos,s_splits)) if np.size(infos) else np.array(s_splits)\n",
    "    \n",
    "    df = pd.read_csv(path_data+'df_pca/'+f, index_col=0)\n",
    "    cols_to_sel = [c for c in df.columns if 'surf' in c]\n",
    "    sel = df[cols_to_sel].loc[['comp 2']].values[0]\n",
    "    all_pca[i,:] += sel\n",
    "\n",
    "data_df = np.concatenate((infos,all_pca), axis=1)\n",
    "df_all = pd.DataFrame(data=data_df, columns=['subject']+cols_to_sel)\n",
    "df_all.to_csv(path_data+'Python/all_spaces_geometry_v=allmod.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87f741",
   "metadata": {},
   "source": [
    "### Statistics and plots - spaces geometry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg \n",
    "v = 'allmod'\n",
    "\n",
    "df_geo0 = pd.read_csv(path_data+'Python/all_spaces_geometry_v=allmod.csv')\n",
    "if v == 'allmod':\n",
    "    df_geo = df_geo0.iloc[:,1:].melt()\n",
    "    df_geo['subjects'] = list(df_geo0['subject'].values)*3\n",
    "\n",
    "    # Plot results \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6,4))\n",
    "    print('>> effect of surf ALL mod ')\n",
    "    df_geo[['value','variable']].boxplot(ax=axes, by='variable')\n",
    "    print(df_geo)\n",
    "    anova = pg.rm_anova(data=df_geo, dv='value', within='variable',\n",
    "                    subject='subjects')\n",
    "    pg.print_table(anova, floatfmt='.3f')\n",
    "\n",
    "    if anova.iloc[0,4] < 0.05:\n",
    "        # Bonf-corrected post hocs with Hedges'g effect size\n",
    "        posthoc = pg.pairwise_tests(data=df_geo, dv='value', within='variable',\n",
    "                            subject='subjects', padjust='bonf')\n",
    "        pg.print_table(posthoc, floatfmt='.3f')\n",
    "    \n",
    "\n",
    "else:\n",
    "    # Plot results \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20,4))\n",
    "    for i,c in enumerate(df_geo.columns[2:]):\n",
    "        print('>> effect of modality on ',c)\n",
    "        df_geo[[c,'stim']].boxplot(ax=axes[i], by='stim')\n",
    "        anova = pg.rm_anova(data=df_geo, dv=c, within='stim',\n",
    "                        subject='subject')\n",
    "        pg.print_table(anova, floatfmt='.3f')\n",
    "\n",
    "        if anova.iloc[0,4] < 0.05:\n",
    "            # Bonf-corrected post hocs with Hedges'g effect size\n",
    "            posthoc = pg.pairwise_tests(data=df_geo, dv=c, within='stim',\n",
    "                                subject='subject', padjust='bonf')\n",
    "            pg.print_table(posthoc, floatfmt='.3f')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b0354a",
   "metadata": {},
   "source": [
    "### Correlation btw perceptual spaces' size and memory v=allmod\n",
    "d' recognition performance and episodic memory performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a323db6a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 df in the same order =>  True\n",
      "REC correl for  all          X              Y   method alternative   n         r          CI95%  \\\n",
      "0  d_prime  surf poly all  pearson   two-sided  48 -0.097134  [-0.37, 0.19]   \n",
      "\n",
      "      p-unc   BF10    power  \n",
      "0  0.511324  0.222  0.10078  \n",
      "2 df in the same order =>  True\n",
      "EPI correl for  all        X              Y   method alternative   n         r          CI95%  \\\n",
      "0  WWW-R            W-R  pearson   two-sided  48 -0.660308  [-0.8, -0.46]   \n",
      "1  WWW-R  surf poly all  pearson   two-sided  48 -0.099611  [-0.37, 0.19]   \n",
      "2    W-R  surf poly all  pearson   two-sided  48  0.108715  [-0.18, 0.38]   \n",
      "\n",
      "          p-unc       BF10     power  \n",
      "0  3.286469e-07  5.556e+04  0.999671  \n",
      "1  5.005590e-01      0.224  0.103498  \n",
      "2  4.620188e-01      0.234  0.114134  \n",
      "2 df in the same order =>  True\n",
      "REC correl for  odor          X               Y   method alternative   n         r          CI95%  \\\n",
      "0  d_prime  surf poly odor  pearson   two-sided  48 -0.028459  [-0.31, 0.26]   \n",
      "\n",
      "      p-unc   BF10     power  \n",
      "0  0.847731  0.183  0.053933  \n",
      "2 df in the same order =>  True\n",
      "EPI correl for  odor        X               Y   method alternative   n         r          CI95%  \\\n",
      "0  WWW-R             W-R  pearson   two-sided  48 -0.660308  [-0.8, -0.46]   \n",
      "1  WWW-R  surf poly odor  pearson   two-sided  48 -0.088444   [-0.36, 0.2]   \n",
      "2    W-R  surf poly odor  pearson   two-sided  48  0.112483  [-0.18, 0.38]   \n",
      "\n",
      "          p-unc       BF10     power  \n",
      "0  3.286469e-07  5.556e+04  0.999671  \n",
      "1  5.499880e-01      0.214  0.091836  \n",
      "2  4.465490e-01      0.238  0.118838  \n",
      "2 df in the same order =>  True\n",
      "REC correl for  music          X                Y   method alternative   n         r          CI95%  \\\n",
      "0  d_prime  surf poly music  pearson   two-sided  48 -0.182648  [-0.44, 0.11]   \n",
      "\n",
      "      p-unc   BF10     power  \n",
      "0  0.214033  0.381  0.239322  \n",
      "2 df in the same order =>  True\n",
      "EPI correl for  music        X                Y   method alternative   n         r          CI95%  \\\n",
      "0  WWW-R              W-R  pearson   two-sided  48 -0.660308  [-0.8, -0.46]   \n",
      "1  WWW-R  surf poly music  pearson   two-sided  48 -0.229791  [-0.48, 0.06]   \n",
      "2    W-R  surf poly music  pearson   two-sided  48  0.055139  [-0.23, 0.33]   \n",
      "\n",
      "          p-unc       BF10     power  \n",
      "0  3.286469e-07  5.556e+04  0.999671  \n",
      "1  1.161415e-01      0.596  0.353331  \n",
      "2  7.097232e-01      0.192  0.065799  \n",
      "2 df in the same order =>  True\n",
      "REC correl for  face          X               Y   method alternative   n         r         CI95%  \\\n",
      "0  d_prime  surf poly face  pearson   two-sided  48  0.020137  [-0.27, 0.3]   \n",
      "\n",
      "      p-unc   BF10     power  \n",
      "0  0.891939  0.182  0.051803  \n",
      "2 df in the same order =>  True\n",
      "EPI correl for  face        X               Y   method alternative   n         r          CI95%  \\\n",
      "0  WWW-R             W-R  pearson   two-sided  48 -0.660308  [-0.8, -0.46]   \n",
      "1  WWW-R  surf poly face  pearson   two-sided  48  0.102370  [-0.19, 0.38]   \n",
      "2    W-R  surf poly face  pearson   two-sided  48  0.043510  [-0.24, 0.32]   \n",
      "\n",
      "          p-unc       BF10     power  \n",
      "0  3.286469e-07  5.556e+04  0.999671  \n",
      "1  4.887086e-01      0.227  0.106613  \n",
      "2  7.690348e-01      0.188  0.059672  \n"
     ]
    }
   ],
   "source": [
    "path_mem = '/Users/alouette/Documents/Perceptual_Space_ALS/old/'\n",
    "stims = ['all','odor','music','face']\n",
    "\n",
    "#load space geometry \n",
    "df_geo = pd.read_csv(path_data+'Python/all_spaces_geometry_v=allmod.csv')\n",
    "df_geo['surf poly all'] = df_geo.iloc[:,1:].mean(axis=1)\n",
    "df_geo = df_geo.sort_values(['subject'])\n",
    "df_geo.columns = ['subject', 'surf poly odor', 'surf poly face', \n",
    "                  'surf poly music','surf poly all']\n",
    "\n",
    "#load df memory perf (select subjects)\n",
    "df_ret = pd.read_excel(path_mem+'all_rappel_score.xls')\n",
    "df_ret = df_ret.loc[df_ret['subject'].isin(subjects_no_out)]\n",
    "\n",
    "for stim in stims:\n",
    "    \n",
    "    #recognition performance\n",
    "    if stim =='all':\n",
    "        df_stim = df_ret\n",
    "    else:\n",
    "        df_stim = df_ret[~df_ret[stim].isna()]\n",
    "    \n",
    "    df_gr = df_ret.groupby(['subject','score_recognition']).count()['trial_num']\n",
    "    df_gr = df_gr.unstack().fillna(0) #replace NaN values by 0\n",
    "    HR = (df_gr['hit'] + 0.5) / (27 + 1)\n",
    "    FR = (df_gr['fa'] + 0.5) / (27 + 1)\n",
    "    df_gr['d_prime'] = np.log((HR* (1 - FR))/(FR * (1 - HR)))\n",
    "    print('2 df in the same order => ', any(df_geo.subject == df_gr.index))\n",
    "\n",
    "    df_tot = df_geo.merge(df_gr, left_on='subject', right_on='subject')\n",
    "    pair_allmod = pg.pairwise_corr(df_tot[['d_prime','surf poly '+stim]], method='pearson')\n",
    "    print('REC correl for ',stim, pair_allmod)\n",
    "\n",
    "    #global episodic performance\n",
    "    df_gr2 = df_ret.groupby(['subject','episodic_score']).count()['trial_num']\n",
    "    df_gr2 = df_gr2.unstack().fillna(0) #replace NaN values by 0\n",
    "    df_gr2['WWW-R'] = (df_gr2['www'] + 0.5) / (27 + 1)\n",
    "    df_gr2['W-R'] = (df_gr2['w'] + 0.5) / (27 + 1)\n",
    "    print('2 df in the same order => ', any(df_geo.subject == df_gr2.index))\n",
    "    \n",
    "    df_tot2 = df_geo.merge(df_gr2, left_on='subject', right_on='subject')\n",
    "    pair_allmod2 = pg.pairwise_corr(df_tot2[['WWW-R','W-R','surf poly '+stim]],method='pearson')\n",
    "    if any(pair_allmod2['p-unc']<0.05):\n",
    "        print('EPI correl for ',stim, pair_allmod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c6ee9",
   "metadata": {},
   "source": [
    "### Explore dist between distactors and targets and its impact on memory performance\n",
    "For ALL sensory modalities together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2dc66032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_btw_groups(gr1, gr2):\n",
    "    pairs = [(p0, p1) for p0, p1 in product(gr1,gr2)]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98263ed7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject           object\n",
      "stimulus_type     object\n",
      "stimulus_name     object\n",
      "coord.Dim.1      float64\n",
      "coord.Dim.2      float64\n",
      "coord.Dim.3      float64\n",
      "coord.Dim.4      float64\n",
      "cos2.Dim.1       float64\n",
      "cos2.Dim.2       float64\n",
      "cos2.Dim.3       float64\n",
      "cos2.Dim.4       float64\n",
      "contrib.Dim.1    float64\n",
      "contrib.Dim.2    float64\n",
      "contrib.Dim.3    float64\n",
      "contrib.Dim.4    float64\n",
      "dist             float64\n",
      "dtype: object {'M02': ['distractor'], '4': ['target'], 'V02': ['target'], '1': ['target'], 'M13': ['target'], 'V08': ['target'], '15': ['distractor'], 'V01': ['target'], 'M17': ['target'], 'V16': ['distractor'], '3': ['target'], 'M03': ['distractor'], 'V05': ['target'], 'M18': ['target'], '17': ['distractor'], 'M06': ['distractor'], 'V14': ['distractor'], '11': ['distractor'], '18': ['distractor'], 'M01': ['distractor'], 'V03': ['target'], '16': ['distractor'], 'M11': ['target'], 'V15': ['distractor'], '5': ['target'], 'M10': ['target'], 'V11': ['distractor'], 'V07': ['target'], '14': ['distractor'], 'V13': ['distractor'], 'M15': ['target'], '2': ['target'], 'V17': ['distractor'], 'V10': ['distractor'], '8': ['distractor'], 'M12': ['target'], 'V09': ['target'], 'M04': ['distractor'], '6': ['target'], 'M14': ['target'], 'V18': ['distractor'], '13': ['distractor'], 'M09': ['distractor'], '10': ['distractor'], 'M16': ['target']}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m su \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS08-BSC\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df_pca\u001b[38;5;241m.\u001b[39mdtypes, dict_su)\n\u001b[0;32m---> 23\u001b[0m df_pca[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df_pca[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstimulus_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(dict_su)]\n\u001b[1;32m     24\u001b[0m gr1 \u001b[38;5;241m=\u001b[39m df_pca\u001b[38;5;241m.\u001b[39mloc[df_pca[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m gr2 \u001b[38;5;241m=\u001b[39m df_pca\u001b[38;5;241m.\u001b[39mloc[df_pca[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistractor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Input \u001b[0;32mIn [87]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m su \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS08-BSC\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df_pca\u001b[38;5;241m.\u001b[39mdtypes, dict_su)\n\u001b[0;32m---> 23\u001b[0m df_pca[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df_pca[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstimulus_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(dict_su)]\n\u001b[1;32m     24\u001b[0m gr1 \u001b[38;5;241m=\u001b[39m df_pca\u001b[38;5;241m.\u001b[39mloc[df_pca[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m gr2 \u001b[38;5;241m=\u001b[39m df_pca\u001b[38;5;241m.\u001b[39mloc[df_pca[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistractor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "files_pca = [f for f in os.listdir(path_data + 'df_pca/') if f.endswith('ALL_PCA.csv')]\n",
    "\n",
    "all_d, all_s = [], []\n",
    "for f in files_pca:\n",
    "    #perceptual space coordinates\n",
    "    df_pca = pd.read_csv(path_data+'df_pca/'+ f, index_col=0)\n",
    "    su = np.unique(df_pca['subject'])[0]\n",
    "\n",
    "    #stimuli config by subject\n",
    "    df_mem = pd.read_excel(path_data+'old/all_rappel_score.xls',index_col=0)\n",
    "    cols = ['subject','face','odor','music','score_recognition','episodic_score']\n",
    "    conf_su = df_mem[cols].loc[df_mem['subject']==su].reset_index().iloc[:,1:]\n",
    "    conf_su = conf_su.fillna('')\n",
    "    conf_su = conf_su.astype(str)\n",
    "    conf_su['odor'] = [r.split('.')[0] for r in conf_su['odor']]\n",
    "    conf_su['stimulus_name'] = conf_su[\"face\"] + conf_su[\"odor\"] + conf_su['music']\n",
    "    conf_su['type'] = [c if c == 'distractor' else 'target' for c in conf_su['episodic_score']]\n",
    "    dict_su = conf_su[['stimulus_name','type']].set_index('stimulus_name').T.to_dict('list')\n",
    "\n",
    "    #add stimuli type in pca files\n",
    "    df_pca['type'] = [x[0] for x in df_pca['stimulus_name'].map(dict_su)]\n",
    "    gr1 = df_pca.loc[df_pca['type']=='target']\n",
    "    gr2 = df_pca.loc[df_pca['type']=='distractor']\n",
    "    pairs = pairs_btw_groups(gr1=gr1.stimulus_name, gr2=gr2.stimulus_name)\n",
    "    dist = np.mean(compute_all_dist(df, pairs, name_col='stimulus_name',\n",
    "                       x_col='coord.Dim.1', y_col='coord.Dim.2'))\n",
    "    all_d.append(dist)\n",
    "    all_s.append(su)\n",
    "sns.histplot(data=all_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "07e36c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         [target]\n",
       "2         [target]\n",
       "3         [target]\n",
       "4              NaN\n",
       "5         [target]\n",
       "6              NaN\n",
       "7         [target]\n",
       "8         [target]\n",
       "9         [target]\n",
       "10    [distractor]\n",
       "11    [distractor]\n",
       "12             NaN\n",
       "13    [distractor]\n",
       "14    [distractor]\n",
       "15    [distractor]\n",
       "16    [distractor]\n",
       "17    [distractor]\n",
       "18    [distractor]\n",
       "19    [distractor]\n",
       "20    [distractor]\n",
       "21    [distractor]\n",
       "22    [distractor]\n",
       "23             NaN\n",
       "24    [distractor]\n",
       "25             NaN\n",
       "26             NaN\n",
       "27    [distractor]\n",
       "28        [target]\n",
       "29        [target]\n",
       "30        [target]\n",
       "31        [target]\n",
       "32        [target]\n",
       "33        [target]\n",
       "34        [target]\n",
       "35        [target]\n",
       "36        [target]\n",
       "37        [target]\n",
       "38    [distractor]\n",
       "39    [distractor]\n",
       "40             NaN\n",
       "41    [distractor]\n",
       "42    [distractor]\n",
       "43    [distractor]\n",
       "44    [distractor]\n",
       "45    [distractor]\n",
       "46    [distractor]\n",
       "47        [target]\n",
       "48        [target]\n",
       "49        [target]\n",
       "50        [target]\n",
       "51        [target]\n",
       "52             NaN\n",
       "53    [distractor]\n",
       "54             NaN\n",
       "Name: stimulus_name, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca['stimulus_name'].map(dict_su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dist = np.zeros((972, len(files_pca)))\n",
    "all_sub = []\n",
    "for i, f in enumerate(files_pca):\n",
    "    df = pd.read_csv(path_data+'df_pca/'+ f, index_col=0)\n",
    "    df['stim_name2'] = ['O'+name if name[0] not in ('M','V') else name for name in df.stimulus_name]\n",
    "    pairs = define_pairs_diff(df.stim_name2)\n",
    "    dist = compute_all_dist(df, pairs, name_col='stim_name2',\n",
    "                       x_col='coord.Dim.1', y_col='coord.Dim.2')\n",
    "    all_dist[:,i] += dist\n",
    "    all_sub.append(df.subject.values[0])\n",
    "\n",
    "data_df = np.concatenate((np.array(pairs),all_dist),axis=1)\n",
    "df_all = pd.DataFrame(data=data_df, columns=['p0','p1']+all_sub)\n",
    "df_all.to_csv(path_data+'Python/all_dist_BTW_stim_v=allmod.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behav",
   "language": "python",
   "name": "behav"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
